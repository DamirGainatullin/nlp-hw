1. Этапы EDA и подготовки данных
1.1. Загрузка данных и очистка
Задача: Проверить, корректно ли загружены данные, есть ли пропуски, дубликаты и ошибки.
Влияние: Некачественные данные или пропуски могут ухудшить качество модели. Очистка и базовая проверка помогают избежать ошибок в дальнейшем.
1.2. Токенизация
Что делается: Разделение текста на отдельные слова или токены.
Задача: Подготовить данные для дальнейшей обработки, так как модели не работают напрямую с "сырым" текстом.
Влияние: Неверная токенизация (например, если игнорируются дефисы или не удаляются знаки препинания) может вносить шум.
1.3. Удаление стоп-слов
Что делается: Исключаются слова, которые не несут значимой информации (например, "и", "в", "на").
Задача: Уменьшить количество нерелевантных токенов и фокусироваться на значимых словах.
Влияние: Позволяет модели лучше сосредоточиться на важных словах, что улучшает предсказание.
1.4. Лемматизация
Что делается: Приведение слов к начальной форме (например, "помогает" → "помогать").
Задача: Снизить вариативность словоформ, чтобы модель лучше понимала смысл.
Влияние: Улучшает согласованность данных и уменьшает размер словаря, что повышает точность и снижает переобучение.
1.5. POS-теггинг (части речи)
Что делается: Определение частей речи (глагол, существительное и т.д.).
Задача: Добавить контекст к данным, помочь выделить важные слова (например, фокусироваться на существительных и глаголах).
Влияние: Может быть полезным при создании дополнительных признаков, например, для акцентирования на определённых типах слов.
